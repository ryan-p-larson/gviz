{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Descriptive Statistics - GPS\n",
    "\n",
    "4-5-17\n",
    "\n",
    "This notebook is to gather a ground truth on how many tweets are geotagged (have a `lat/lon`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "ext_dir = '../data/external/'\n",
    "proc_dir = '../data/processed/'\n",
    "\n",
    "scrape_in = ext_dir + 'scrape/'\n",
    "scrape_out = proc_dir + 'scrape/4-5/{}-gps.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Objectives**\n",
    "\n",
    "Get an aggregated count over time. For each day we should have \n",
    "1. The date\n",
    "2. Languages\n",
    "3. GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "def parallelize_series(series, func):\n",
    "    pool = Pool(6)\n",
    "\n",
    "    df = pool.map(func, series)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_scrape_gps(csv):\n",
    "    \"\"\"Does the heavy lifting to process one csv\n",
    "    \"\"\"\n",
    "    agg_cols = ['language', 'date', 'latitude']\n",
    "    df = pd.read_csv(csv, usecols=agg_cols,\n",
    "                     parse_dates=['date'],\n",
    "                    infer_datetime_format=True)\n",
    "    \n",
    "    # Drop rows that'll give us trouble\n",
    "    df['date'].dropna(how='any', inplace=True)\n",
    "    \n",
    "    # add day column so we can groupby\n",
    "    df['day'] = df['date'].dt.date\n",
    "    \n",
    "    # get the ground truth for numbers\n",
    "    # LOGIC: every tweet has to have been created at some point, every tweet has a date\n",
    "    without_gps = df[['day', 'language', 'date']].groupby(['day', 'language']).count()\n",
    "    \n",
    "    # get gps numbers\n",
    "    with_gps = df[['day', 'language', 'latitude']].groupby(['day', 'language']).count()\n",
    "    \n",
    "    # combine them\n",
    "    gps_df = pd.concat([with_gps, without_gps], axis=1)\n",
    "    \n",
    "    # rename columns \n",
    "    gps_df.columns = ['gps', 'wo_gps']\n",
    "    \n",
    "    return gps_df\n",
    "\n",
    "def process_scrape_f(f):\n",
    "     # file names\n",
    "    f_in = scrape_in + f\n",
    "    f_out = scrape_out.format(f[:-4])\n",
    "    \n",
    "    # sanity check for times sake\n",
    "    if (os.path.isfile(f_in) == False):\n",
    "        return\n",
    "    else:\n",
    "        try:\n",
    "            grouped_df = process_scrape_gps(f_in)\n",
    "            grouped_df.to_csv(f_out)\n",
    "            print (\"...{}\".format(f))\n",
    "        except:\n",
    "            print (\"Couldn't read {}\".format(f))\n",
    "    \n",
    "#process_scrape_agg(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# List of all the files we'll be evaluating\n",
    "\n",
    "# testing\n",
    "#scrape_fs = os.listdir(scrape_in)\n",
    "\n",
    "# 'production'\n",
    "scrape_fs = [x for x in  os.listdir(scrape_in)\n",
    "           if (x.split('.')[0][-4:] != '_log')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...tweets_immigrant_34360.csv\n",
      "...tweets_immigrant_34342.csv\n",
      "Couldn't read tweets_immigrant_34324.csv\n",
      "...tweets_immigrant_34315.csv\n",
      "...tweets_immigrant_34333.csv\n",
      "...tweets_immigrant_34316.csv\n",
      "...tweets_immigrant_34334.csv\n",
      "...tweets_immigrant_34325.csv\n",
      "...tweets_immigrant_34326.csv\n",
      "...tweets_immigrant_34343.csv\n",
      "...tweets_immigrant_34351.csv\n",
      "...tweets_immigrant_34361.csv\n",
      "...tweets_immigrant_34344.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlrson/anaconda3/envs/gviz/lib/python3.6/multiprocessing/pool.py:119: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  result = (True, func(*args, **kwds))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...tweets_immigrant_34362.csv\n",
      "...tweets_immigrant_34352.csv\n",
      "Couldn't read tweets_immigrant_34345.csv\n",
      "...tweets_immigrant_34335.csv\n",
      "...tweets_immigrant_34346.csv\n",
      "...tweets_immigrant_34336.csv\n",
      "...tweets_immigrant_34317.csv\n",
      "...tweets_immigrant_34318.csv\n",
      "...tweets_immigrant_34327.csv\n",
      "...tweets_immigrant_34328.csv\n",
      "...tweets_immigrant_34319.csv\n",
      "...tweets_immigrant_34363.csv\n",
      "...tweets_immigrant_34320.csv\n",
      "...tweets_immigrant_34329.csv\n",
      "...tweets_immigrant_34353.csv\n",
      "...tweets_immigrant_34364.csv\n",
      "...tweets_immigrant_34330.csv\n",
      "...tweets_immigrant_34354.csv\n",
      "...tweets_immigrant_34347.csv\n",
      "...tweets_immigrant_34348.csv\n",
      "...tweets_immigrant_34337.csv\n",
      "...tweets_immigrant_34338.csv\n",
      "...tweets_immigrant_34321.csv\n",
      "Couldn't read tweets_immigrant_34322.csv\n",
      "...tweets_immigrant_34331.csv\n",
      "...tweets_immigrant_34332.csv\n",
      "...tweets_immigrant_34365.csv\n",
      "...tweets_immigrant_34366.csv\n",
      "...tweets_immigrant_34349.csv\n",
      "...tweets_immigrant_34339.csv\n",
      "...tweets_immigrant_34355.csv\n",
      "...tweets_immigrant_34350.csv\n",
      "...tweets_immigrant_34340.csv\n",
      "...tweets_immigrant_34356.csv\n",
      "...tweets_immigrant_34378.csv\n",
      "...tweets_immigrant_34323.csv\n",
      "...tweets_immigrant_34369.csv\n",
      "...tweets_immigrant_34370.csv\n",
      "...tweets_immigrant_34367.csv\n",
      "...tweets_immigrant_34368.csv\n",
      "...tweets_immigrant_34341.csv\n",
      "...tweets_immigrant_34396.csv\n",
      "...tweets_immigrant_34379.csv\n",
      "...tweets_immigrant_34357.csv\n",
      "...tweets_immigrant_34380.csv\n",
      "...tweets_immigrant_34358.csv\n",
      "...tweets_immigrant_34371.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlrson/anaconda3/envs/gviz/lib/python3.6/multiprocessing/pool.py:119: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  result = (True, func(*args, **kwds))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...tweets_immigrant_34359.csv\n",
      "...tweets_immigrant_34414.csv\n",
      "...tweets_immigrant_34405.csv\n",
      "...tweets_immigrant_34406.csv\n",
      "...tweets_immigrant_34387.csv\n",
      "...tweets_immigrant_34381.csv\n",
      "...tweets_immigrant_34382.csv\n",
      "...tweets_immigrant_34388.csv\n",
      "...tweets_immigrant_34397.csv\n",
      "...tweets_immigrant_34398.csv\n",
      "Couldn't read tweets_immigrant_34372.csv\n",
      "Couldn't read tweets_immigrant_34373.csv\n",
      "...tweets_immigrant_34374.csv\n",
      "...tweets_immigrant_34415.csv\n",
      "...tweets_immigrant_34407.csv\n",
      "...tweets_immigrant_34416.csv\n",
      "...tweets_immigrant_34408.csv\n",
      "...tweets_immigrant_34383.csv\n",
      "...tweets_immigrant_34375.csv\n",
      "...tweets_immigrant_34384.csv\n",
      "...tweets_immigrant_34376.csv\n",
      "...tweets_immigrant_34399.csv\n",
      "...tweets_immigrant_34400.csv\n",
      "Couldn't read tweets_immigrant_34401.csv\n",
      "...tweets_immigrant_34402.csv\n",
      "...tweets_immigrant_34417.csv\n",
      "...tweets_immigrant_34409.csv\n",
      "...tweets_immigrant_34418.csv\n",
      "...tweets_immigrant_34410.csv\n",
      "...tweets_immigrant_34377.csv\n",
      "...tweets_immigrant_34385.csv\n",
      "...tweets_immigrant_34386.csv\n",
      "...tweets_immigrant_34389.csv\n",
      "...tweets_immigrant_34419.csv\n",
      "...tweets_immigrant_34432.csv\n",
      "...tweets_immigrant_34420.csv\n",
      "...tweets_immigrant_34403.csv\n",
      "...tweets_immigrant_34404.csv\n",
      "...tweets_immigrant_34390.csv\n",
      "...tweets_immigrant_34411.csv\n",
      "...tweets_immigrant_34412.csv\n",
      "...tweets_immigrant_34423.csv\n",
      "...tweets_immigrant_34424.csv\n",
      "...tweets_immigrant_34441.csv\n",
      "...tweets_immigrant_34442.csv\n",
      "...tweets_immigrant_34421.csv\n",
      "...tweets_immigrant_34422.csv\n",
      "...tweets_immigrant_34450.csv\n",
      "...tweets_immigrant_34433.csv\n",
      "...tweets_immigrant_34434.csv\n",
      "...tweets_immigrant_34425.csv\n",
      "...tweets_immigrant_34426.csv\n",
      "...tweets_immigrant_34413.csv\n",
      "...tweets_immigrant_34443.csv\n",
      "...tweets_immigrant_34444.csv\n",
      "...tweets_immigrant_34435.csv\n",
      "...tweets_immigrant_34451.csv\n",
      "...tweets_immigrant_34436.csv\n",
      "...tweets_immigrant_34452.csv\n",
      "...tweets_immigrant_34427.csv\n",
      "...tweets_immigrant_34459.csv\n",
      "...tweets_immigrant_34428.csv\n",
      "...tweets_immigrant_34460.csv\n",
      "...tweets_immigrant_34391.csv\n",
      "...tweets_immigrant_34392.csv\n",
      "...tweets_immigrant_34445.csv\n",
      "...tweets_immigrant_34446.csv\n",
      "...tweets_immigrant_34461.csv\n",
      "...tweets_immigrant_34462.csv\n",
      "...tweets_immigrant_34453.csv\n",
      "...tweets_immigrant_34437.csv\n",
      "...tweets_immigrant_34454.csv\n",
      "...tweets_immigrant_34429.csv\n",
      "...tweets_immigrant_34438.csv\n",
      "...tweets_immigrant_34430.csv\n",
      "...tweets_immigrant_34447.csv\n",
      "...tweets_immigrant_34448.csv\n",
      "...tweets_immigrant_34455.csv\n",
      "...tweets_immigrant_34439.csv\n",
      "...tweets_immigrant_34456.csv\n",
      "...tweets_immigrant_34431.csv\n",
      "...tweets_immigrant_34463.csv\n",
      "...tweets_immigrant_34440.csv\n",
      "...tweets_immigrant_34464.csv\n",
      "...tweets_immigrant_34449.csv\n",
      "...tweets_immigrant_34486.csv\n",
      "Couldn't read tweets_immigrant_34468.csv\n",
      "...tweets_immigrant_34477.csv\n",
      "...tweets_immigrant_34478.csv\n",
      "...tweets_immigrant_34457.csv\n",
      "...tweets_immigrant_34458.csv\n",
      "...tweets_immigrant_34465.csv\n",
      "...tweets_immigrant_34466.csv\n",
      "...tweets_immigrant_34393.csv\n",
      "...tweets_immigrant_34394.csv\n",
      "...tweets_immigrant_34487.csv\n",
      "...tweets_immigrant_34488.csv\n",
      "...tweets_immigrant_34479.csv\n",
      "...tweets_immigrant_34469.csv\n",
      "...tweets_immigrant_34480.csv\n",
      "...tweets_immigrant_34470.csv\n",
      "...tweets_immigrant_34467.csv\n",
      "...tweets_immigrant_34504.csv\n",
      "...tweets_immigrant_34495.csv\n",
      "...tweets_immigrant_34496.csv\n",
      "...tweets_immigrant_34489.csv\n",
      "...tweets_immigrant_34490.csv\n",
      "...tweets_immigrant_34471.csv\n",
      "...tweets_immigrant_34472.csv\n",
      "...tweets_immigrant_34481.csv\n",
      "...tweets_immigrant_34482.csv\n",
      "...tweets_immigrant_34505.csv\n",
      "...tweets_immigrant_34506.csv\n",
      "...tweets_immigrant_34395.csv\n",
      "...tweets_immigrant_34491.csv\n",
      "...tweets_immigrant_34492.csv\n",
      "...tweets_immigrant_34473.csv\n",
      "...tweets_immigrant_34474.csv\n",
      "...tweets_immigrant_34497.csv\n",
      "...tweets_immigrant_34498.csv\n",
      "...tweets_immigrant_34507.csv\n",
      "...tweets_immigrant_34483.csv\n",
      "...tweets_immigrant_34508.csv\n",
      "...tweets_immigrant_34484.csv\n",
      "...tweets_immigrant_34513.csv\n",
      "...tweets_immigrant_34514.csv\n",
      "...tweets_immigrant_34493.csv\n",
      "...tweets_immigrant_34499.csv\n",
      "...tweets_immigrant_34494.csv\n",
      "...tweets_immigrant_34475.csv\n",
      "...tweets_immigrant_34522.csv\n",
      "...tweets_immigrant_34500.csv\n",
      "...tweets_immigrant_34476.csv\n",
      "...tweets_immigrant_34485.csv\n",
      "...tweets_immigrant_34509.csv\n",
      "...tweets_immigrant_34510.csv\n",
      "...tweets_immigrant_34515.csv\n",
      "...tweets_immigrant_34516.csv\n",
      "...tweets_immigrant_34501.csv\n",
      "...tweets_immigrant_34502.csv\n",
      "...tweets_immigrant_34517.csv\n",
      "...tweets_immigrant_34518.csv\n",
      "...tweets_immigrant_34511.csv\n",
      "...tweets_immigrant_34512.csv\n",
      "...tweets_immigrant_34503.csv\n",
      "...tweets_immigrant_34519.csv\n",
      "...tweets_immigrant_34520.csv\n",
      "...tweets_immigrant_34521.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallelize_series(scrape_fs, process_scrape_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Combining individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# list all newly processed files \n",
    "gps_fs = os.listdir((proc_dir + 'scrape/4-5/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prep_gps_csv(csv):\n",
    "    \"\"\"Reads a csv in, sets the multiindex, and returns it\"\"\"\n",
    "    df = pd.read_csv(csv)\n",
    "    df.set_index(['day', 'language'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create one frame out of all of them\n",
    "all_gps = pd.concat([prep_gps_csv((proc_dir+'scrape/4-5/'+x)) for x in gps_fs])\n",
    "\n",
    "# Add all the days/langs up\n",
    "all_gps = all_gps.groupby(level=[0, 1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "all_gps.to_csv((proc_dir+'scrape/4-5/all-gps.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>gps</th>\n",
       "      <th>wo_gps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>language</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2016-12-22</th>\n",
       "      <th>ar</th>\n",
       "      <td>348</td>\n",
       "      <td>8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>12</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>el</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gps  wo_gps\n",
       "day        language             \n",
       "2016-12-22 ar        348    8464\n",
       "           ca          0      10\n",
       "           cs          0       2\n",
       "           de         12     180\n",
       "           el          0       6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_gps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "Rollup the languages to day sums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>language</th>\n",
       "      <th>gps</th>\n",
       "      <th>wo_gps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>ar</td>\n",
       "      <td>348</td>\n",
       "      <td>8464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>ca</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>cs</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>de</td>\n",
       "      <td>12</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>el</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day language  gps  wo_gps\n",
       "0  2016-12-22       ar  348    8464\n",
       "1  2016-12-22       ca    0      10\n",
       "2  2016-12-22       cs    0       2\n",
       "3  2016-12-22       de   12     180\n",
       "4  2016-12-22       el    0       6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_gps = pd.read_csv((proc_dir+'scrape/4-5/all-gps.csv'))\n",
    "all_gps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "day_gps = all_gps[['day', 'gps', 'wo_gps']].groupby(['day']).sum()\n",
    "day_gps.to_csv((proc_dir+'scrape/4-5/day-gps.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
