{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Tweet Database\n",
    "\n",
    "Create a sqlLite database that we can use for faster indexing.\n",
    "\n",
    "**Links:**\n",
    "- [Twitter Streaming with Python and SQLite, David Schuler](http://www.davidrschuler.com/python_twitter_streaming)\n",
    "- [Working with SQLite Databases using Python and Pandas, DataQuest](https://www.dataquest.io/blog/python-pandas-databases/)\n",
    "- [Big Data Analytics with Pandas and SQLite in Python, Plotly](https://plot.ly/ipython-notebooks/big-data-analytics-with-pandas-and-sqlite/)\n",
    "\n",
    "<br>\n",
    "```\n",
    "df.to_sql(\"table_name\", conn, if_exists=\"replace/append\")        # write\n",
    "pd.read_sql_query(\"select * from table_name limit 1;\", conn)     # read\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "%run utilities.py\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run two commands to create/clear the database\n",
    "!rm ../../data/processed/scrape/raw-tweets.db\n",
    "!touch ../../data/processed/scrape/raw-tweets.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variables and Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Schemas\n",
    "raw_schema = \"\"\"CREATE TABLE IF NOT EXISTS Raw(\n",
    "  tweetID INTEGER,\n",
    "  date DATE,\n",
    "  week DATE,\n",
    "  username TEXT,\n",
    "  message TEXT,\n",
    "  retweet INTEGER,\n",
    "  longitude REAL,\n",
    "  latitude REAL,\n",
    "  followersCount INTEGER,\n",
    "  friendsCount INTEGER,\n",
    "  joinDay TEXT,\n",
    "  favouritesCount INTEGER,\n",
    "  language TEXT,\n",
    "  statusesCount INTEGER\n",
    ");\"\"\".replace('\\n', '')\n",
    "\n",
    "def filter_tweet_df(raw_df):\n",
    "    \"\"\"\n",
    "    Formats and returns a dataframe of tweets\n",
    "    \"\"\"\n",
    "    dt_parser = lambda x: pd.to_datetime(x, infer_datetime_format=True) # format=\"%b-%d-%Y\")\n",
    "    #dt_parser = lambda t: t.split()[1] +'-'+ t.split()[2] +'-'+ t.split()[-1]\n",
    "    \n",
    "    # Drop rows that'll give us trouble\n",
    "    raw_df.dropna(subset=['date', 'longitude', 'latitude', 'message'], how='any', inplace=True)\n",
    "    raw_df['week'] = raw_df['date'].map(dt_parser)\n",
    "    \n",
    "    return raw_df\n",
    "    \n",
    "def read_tweets(f):\n",
    "    conversions = {'retweet': lambda x: 1 if (x=='RT') else x\n",
    "                  #'date': lambda t: t.split()[1] +'-'+ t.split()[2] +'-'+ t.split()[-1]\n",
    "                  }\n",
    "    raw_df = pd.read_csv(f, usecols=cols_all,    # filtering\n",
    "                         low_memory=False, engine='c', # optimization\n",
    "                        converters=conversions)        # format attrs\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# start\n",
    "conn = sqlite3.connect(tweet_db_f)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add table to database\n",
    "cur.execute(raw_schema)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table Raw has no column named userID",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-83d5e7731d12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mslim_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilter_tweet_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mslim_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"append\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\rlrson\\AppData\\Local\\conda\\conda\\envs\\gviz\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1343\u001b[0m         sql.to_sql(self, name, con, flavor=flavor, schema=schema,\n\u001b[0;32m   1344\u001b[0m                    \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1345\u001b[1;33m                    chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[0;32m   1346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'infer'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rlrson\\AppData\\Local\\conda\\conda\\envs\\gviz\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, flavor, schema, if_exists, index, index_label, chunksize, dtype)\u001b[0m\n\u001b[0;32m    469\u001b[0m     pandas_sql.to_sql(frame, name, if_exists=if_exists, index=index,\n\u001b[0;32m    470\u001b[0m                       \u001b[0mindex_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m                       chunksize=chunksize, dtype=dtype)\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rlrson\\AppData\\Local\\conda\\conda\\envs\\gviz\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1504\u001b[0m                             dtype=dtype)\n\u001b[0;32m   1505\u001b[0m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1506\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhas_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\rlrson\\AppData\\Local\\conda\\conda\\envs\\gviz\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, chunksize)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                 \u001b[0mchunk_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_i\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m     def _query_iterator(self, result, chunksize, columns, coerce_float=True,\n",
      "\u001b[1;32mC:\\Users\\rlrson\\AppData\\Local\\conda\\conda\\envs\\gviz\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36m_execute_insert\u001b[1;34m(self, conn, keys, data_iter)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_execute_insert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m         \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1294\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecutemany\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_statement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_create_table_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: table Raw has no column named userID"
     ]
    }
   ],
   "source": [
    "# add tweets to new DB table \n",
    "tweets_list = ls_files_list(external_scrape_dir)\n",
    "\n",
    "for tweets in tweets_list[1:]:\n",
    "    tweet_df = read_tweets(tweets)\n",
    "    slim_df = filter_tweet_df(tweet_df)\n",
    "    \n",
    "    slim_df.to_sql(\"Raw\", conn, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add changes and close\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
