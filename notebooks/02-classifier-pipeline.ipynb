{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Classifier Pipeline\n",
    "\n",
    "**First**, let's import our libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.config/anaconda3/envs/gviz/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# round of lib imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report as clsr\n",
    "from sklearn.cross_validation import train_test_split as tts\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "**data in...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y2</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Warn penni board will make you faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Fuck dyke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  y2                                      X\n",
       "0  1   0  Warn penni board will make you faggot\n",
       "1  2   1                              Fuck dyke"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier data\n",
    "f_out = '../data/processed/class/classifier-cleaned.csv'\n",
    "df = pd.read_csv(f_out)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split here!\n",
    "X_train, X_test, y_train, y_test = tts(df.X.values, df.y2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_model(X_test, y_test, clf):\n",
    "    \n",
    "    \n",
    "    res = clf.predict(X_test)\n",
    "\n",
    "    print (confusion_matrix(y_test, res))\n",
    "    print (clsr(y_test, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "---\n",
    "\n",
    "**Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# params\n",
    "parameters = {\n",
    "    # CountVector\n",
    "    'vect__max_df': (0.25, 0.5, 1.0),\n",
    "    'vect__max_features': (5000, 10000, 15000),\n",
    "    'vect__ngram_range': ((1,1), (1,2), (1,3), (2,3)),\n",
    "    'vect__stop_words': (None, 'english'),\n",
    "    #'vect__preprocessor': ()\n",
    "    \n",
    "    # Tfidf Trans\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__smooth_idf': (True, False),\n",
    "    'tfidf__sublinear_tf': (True, False),\n",
    "    \n",
    "    # clf\n",
    "    'clf__C': (0.5, 1, 2),\n",
    "    'clf__class_weight': (None, 'balanced'),\n",
    "    'clf__max_iter': (500, 1000, 2500, 5000)\n",
    "}\n",
    "\n",
    "parameters_test = {\n",
    "    # CountVector\n",
    "    'vect__max_df': (0.25, 0.5, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))]),\n",
       "       fit_params={}, iid=True, n_jobs=4,\n",
       "       param_grid={'vect__max_df': (0.25, 0.5, 1.0)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters_test, n_jobs=4, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Done!** -- Print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.845\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__class_weight: None\n",
      "\tclf__max_iter: 1000\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__smooth_idf: True\n",
      "\ttfidf__sublinear_tf: False\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 1)\n",
      "\tvect__stop_words: None\n",
      "\n",
      "[[2860  185]\n",
      " [ 379  203]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.94      0.91      3045\n",
      "          1       0.52      0.35      0.42       582\n",
      "\n",
      "avg / total       0.83      0.84      0.83      3627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "print ()\n",
    "# see detaailed scores\n",
    "test_model(X_test, y_test, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving** -- to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "out = '../data/processed/class/3-28/'\n",
    "\n",
    "# Model\n",
    "out_model = out + 'model.pkl'\n",
    "joblib.dump(grid_search.best_estimator_, out_model)\n",
    "\n",
    "# Log\n",
    "out_log = out + 'params.txt'\n",
    "with open(out_log, 'w') as f:\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        temp = param_name +': ' + str(best_parameters[param_name])\n",
    "        f.write(temp)\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
